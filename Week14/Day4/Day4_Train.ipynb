{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day4-Train",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bhjj36y8XK5O"
      },
      "source": [
        "!pip install git+git://github.com/PnS2019/pnslib.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGtdeHdxW6o0"
      },
      "source": [
        "import cv2\n",
        "from pnslib import utils\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6iYaZVsXPqE"
      },
      "source": [
        "# https://drive.google.com/file/d/1KM-J0nqm3mKudX2epgVHhB3y8ieglkAA/view?usp=sharing\n",
        "video_input_path = \"/content/drive/My Drive/Colab Notebooks/programmers/YOLO.mp4\"\n",
        "# linux에서 video output의 확장자는 반드시 avi 로 설정 필요. \n",
        "video_output_path = \"/content/drive/My Drive/Colab Notebooks/programmers/YOLO.avi\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMp3Cd30Xhkc"
      },
      "source": [
        "cap = cv2.VideoCapture(video_input_path)\n",
        "# Codec은 *'XVID'로 설정. \n",
        "codec = cv2.VideoWriter_fourcc(*'XVID')\n",
        "\n",
        "vid_size = (round(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),round(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))) #(200, 400)\n",
        "vid_fps = cap.get(cv2.CAP_PROP_FPS )\n",
        "    \n",
        "vid_writer = cv2.VideoWriter(video_output_path, codec, vid_fps, vid_size) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_2aCtxJXxR2"
      },
      "source": [
        "face_cascade = cv2.CascadeClassifier(\n",
        "    utils.get_haarcascade_path('haarcascade_frontalface_default.xml'))\n",
        "eye_cascade = cv2.CascadeClassifier(\n",
        "    utils.get_haarcascade_path('haarcascade_eye.xml'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbeKOFN7XpHi"
      },
      "source": [
        "green_color=(0, 255, 0)\n",
        "red_color=(0, 0, 255)\n",
        "\n",
        "start = time.time()\n",
        "index=0\n",
        "\n",
        "while True:\n",
        "    hasFrame, img_frame = cap.read()\n",
        "    if not hasFrame:\n",
        "        print('더 이상 처리할 frame이 없습니다.')\n",
        "        break\n",
        "    index += 1\n",
        "\n",
        "    gray = cv2.cvtColor(img_frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "\n",
        "    for (x, y, w, h) in faces:\n",
        "      cv2.rectangle(img_frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "      roi_gray = gray[y:y+h, x:x+w]\n",
        "      roi_color = img_frame[y:y+h, x:x+w]\n",
        "      eyes = eye_cascade.detectMultiScale(roi_gray)\n",
        "      for (ex, ey, ew, eh) in eyes:\n",
        "        cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (0, 255, 0), 2)\n",
        "\n",
        "    print('frame :', index, '처리 완료')\n",
        "\n",
        "    vid_writer.write(img_frame)\n",
        "\n",
        "print('write 완료 시간:', round(time.time()-start,4))\n",
        "vid_writer.release()\n",
        "cap.release()   "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}