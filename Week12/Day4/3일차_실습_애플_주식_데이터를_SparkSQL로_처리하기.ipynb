{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [conda root]",
      "language": "python",
      "name": "conda-root-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.3"
    },
    "colab": {
      "name": "3일차 실습: 애플 주식 데이터를 SparkSQL로 처리하기",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYwHJBmiz6e5"
      },
      "source": [
        "어제 실습에 사용한 애플 주식 데이터를 SparkSQL을 가지고 동일한 데이터 분석을 해보자. 모든 답은 Pyspark의 SparkSQL을 통해 이뤄져야 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE0VhL0g1no8"
      },
      "source": [
        "먼저 PySpark과 Py4J를 설치하자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXgIyS_F0Kar"
      },
      "source": [
        "!pip install pyspark==3.0.1 py4j==0.10.9 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNwc3F_Az6e6"
      },
      "source": [
        "#### Spark Session 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "RveyavjYz6e7"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Python Spark SQL basic example\") \\\n",
        "    .getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0DgR89Sz6e8"
      },
      "source": [
        "#### 애플 주식 CSV 파일 로딩하기: https://pyspark-test-sj.s3-us-west-2.amazonaws.com/appl_stock.csv\n",
        "일단 pandas 데이터프레임으로 로딩해서 Spark 데이터프레임으로 변경한다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "FeKmU3Piz6e8"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "apple_pandas_df = pd.read_csv(\"https://pyspark-test-sj.s3-us-west-2.amazonaws.com/appl_stock.csv\")\n",
        "apple_spark_df = spark.createDataFrame(apple_pandas_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMPH1EyR6sSK"
      },
      "source": [
        "apple_spark_df에 apple_stock이라는 테이블 이름을 준다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyqhjBsC6nL4"
      },
      "source": [
        "apple_spark_df.createOrReplaceTempView(\"apple_stock\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXj2LCWuz6e_"
      },
      "source": [
        "#### 1> 스키마를 프린트해보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQR5dwZjz6e_"
      },
      "source": [
        "spark.sql(\"desc apple_stock\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFljhmp5z6fA"
      },
      "source": [
        "#### 2> 처음 5개의 레코드를 출력해보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJQZ7PZDz6fA"
      },
      "source": [
        "spark.sql(\"SELECT * FROM apple_stock LIMIT 5\").show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eR1QL8-Z2auU"
      },
      "source": [
        "#### 3> Close 컬럼의 평균값은 얼마인가?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCQCMa0xz6fB"
      },
      "source": [
        "spark.sql(\"SELECT AVG(close) FROM apple_stock\").show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnE6Cbg_IONn"
      },
      "source": [
        "#### 4> Volume 컬럼의 최대값과 최소값은?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5mvFy0eIVPx"
      },
      "source": [
        "spark.sql(\"SELECT MAX(volume), MIN(volume) FROM apple_stock\").show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ax1Of8ATz6fD"
      },
      "source": [
        "#### 보너스 질문: HV ratio라는 이름의 새로운 컬럼을 추가한 데이터프레임을 만들기. 이 컬럼의 값은 High/Volume으로 계산된다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkO7rQ3Pz6fD"
      },
      "source": [
        "apple_spark_df_with_hv = spark.sql(\n",
        "    \"\"\"SELECT *, high/volume as hvratio FROM apple_stock\"\"\"\n",
        ")   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ce_bSkvOHEDC"
      },
      "source": [
        "apple_spark_df_with_hv.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIROQ8klz6fD"
      },
      "source": [
        "#### 보너스 질문: 월별 Close 컬럼의 평균값은?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_mr0fO_z6fD"
      },
      "source": [
        "spark.sql(\"SELECT Month(date) month, AVG(close) FROM apple_stock GROUP BY 1 ORDER BY 1\").show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}