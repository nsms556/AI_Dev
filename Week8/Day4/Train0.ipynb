{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3512db7f",
   "metadata": {},
   "source": [
    "## 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f84c14d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:51:13.401416Z",
     "start_time": "2021-06-18T07:51:12.746046Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24abe8a",
   "metadata": {},
   "source": [
    "## Computational Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb5b28b",
   "metadata": {},
   "source": [
    "### NumPy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34a7745c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:51:14.225357Z",
     "start_time": "2021-06-18T07:51:14.206371Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "N, D = 3, 4\n",
    "x = np.random.randn(N, D)\n",
    "y = np.random.randn(N, D)\n",
    "z = np.random.randn(N, D)\n",
    "\n",
    "a = x * y\n",
    "b = a + z\n",
    "c = np.sum(b)\n",
    "\n",
    "grad_c = 1.0\n",
    "grad_b = grad_c * np.ones((N, D))\n",
    "grad_a = grad_b.copy()\n",
    "grad_z = grad_b.copy()\n",
    "grad_x = grad_a * y\n",
    "grad_y = grad_a * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4868d347",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:51:20.253389Z",
     "start_time": "2021-06-18T07:51:20.230405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.76103773,  0.12167502,  0.44386323,  0.33367433],\n",
       "       [ 1.49407907, -0.20515826,  0.3130677 , -0.85409574],\n",
       "       [-2.55298982,  0.6536186 ,  0.8644362 , -0.74216502]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b68413",
   "metadata": {},
   "source": [
    "### PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1863b061",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:51:31.587139Z",
     "start_time": "2021-06-18T07:51:31.563245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2375, -0.4777, -0.3602,  0.2041],\n",
      "        [ 0.5741,  0.7695,  0.0246,  1.3220],\n",
      "        [-0.4703,  0.5159, -0.3740,  0.8713]])\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "device = 'cuda' if is_cuda else 'cpu'\n",
    "\n",
    "N, D = 3, 4\n",
    "x = torch.randn(N, D, requires_grad=True, device=device)\n",
    "y = torch.randn(N, D, device=device)\n",
    "z = torch.randn(N, D, device=device)\n",
    "\n",
    "a = x * y\n",
    "b = a + z\n",
    "c = torch.sum(b)\n",
    "\n",
    "c.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e64a03",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2ceb5f",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65377171",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 직접 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a611e90d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:51:33.669627Z",
     "start_time": "2021-06-18T07:51:33.310967Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "x = torch.randn(N, D_in, device=device)\n",
    "y = torch.randn(N, D_out, device=device)\n",
    "w1 = torch.randn(D_in, H, device=device)\n",
    "w2 = torch.randn(H, D_out, device=device)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500) :\n",
    "    h = x.mm(w1)\n",
    "    h_relu = h.clamp(min=0)\n",
    "    y_pred = h_relu.mm(w2)\n",
    "    \n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    \n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "    grad_h = grad_h_relu.clone()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.t().mm(grad_h)\n",
    "    \n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214f0bce",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Autograd 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "616d3a53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:57:05.734884Z",
     "start_time": "2021-06-18T07:57:05.244172Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.5696,  0.4357,  0.8706,  ..., -0.1720,  2.0008,  1.8849],\n",
       "         [-1.7577, -0.5078,  0.1283,  ..., -0.0257,  0.5639, -0.4977],\n",
       "         [ 1.0603, -0.6733,  0.4327,  ...,  1.7146, -0.0470,  0.0271],\n",
       "         ...,\n",
       "         [-0.2729, -1.0909, -0.1624,  ...,  0.0769,  0.9066, -0.4561],\n",
       "         [-0.8741, -0.3212, -0.3699,  ...,  1.9232, -0.2111, -0.6045],\n",
       "         [-0.3825, -0.7857,  0.4174,  ..., -0.1628, -0.7185, -0.7904]],\n",
       "        requires_grad=True),\n",
       " tensor([[ 8.9947e-01,  1.2585e+00, -1.0133e+00,  2.2679e-01,  1.9468e-01,\n",
       "           6.6002e-01,  2.3521e+00,  1.1097e+00, -8.9030e-01, -1.5406e+00],\n",
       "         [ 1.7537e-01, -4.3232e-02,  6.4440e-01,  1.2474e+00,  8.6388e-01,\n",
       "          -2.5684e-01, -1.0790e+00,  5.6755e-01, -4.7203e-01, -4.7542e-01],\n",
       "         [ 3.6652e-02, -5.8028e-01, -5.9648e-01,  9.4549e-01,  7.7446e-01,\n",
       "          -2.9398e-01,  3.8954e-01,  1.2850e+00,  1.1444e+00, -6.2753e-01],\n",
       "         [ 4.8031e-01, -2.7198e-01,  1.0482e+00,  1.2393e+00, -6.0090e-02,\n",
       "          -3.2236e-01, -6.3476e-01, -1.7860e+00,  8.1776e-02,  1.4120e+00],\n",
       "         [ 4.5600e-01,  3.7660e-01, -1.1460e+00, -9.3503e-01,  1.2075e-01,\n",
       "           8.9312e-01, -7.5959e-01,  7.3640e-01,  6.1536e-01,  7.0351e-01],\n",
       "         [ 7.4505e-01,  7.3272e-01,  8.9691e-01,  1.1386e+00,  7.4527e-01,\n",
       "          -1.8050e-01, -4.2311e-01,  1.5452e+00, -9.3063e-01, -5.7096e-01],\n",
       "         [ 8.2920e-01,  1.1582e+00, -4.7374e-01, -9.0007e-01,  9.2866e-02,\n",
       "           7.9554e-02,  7.4561e-01,  2.3579e-01,  1.0014e+00, -1.2346e-01],\n",
       "         [-2.5271e-01, -1.3736e+00, -7.6503e-01,  6.4053e-01,  8.7218e-01,\n",
       "           2.9785e-01, -8.9201e-01,  1.6698e+00,  1.0952e+00,  1.5897e-01],\n",
       "         [ 4.0299e-01,  3.3974e-01, -5.1155e-01,  6.7756e-01, -9.6694e-02,\n",
       "          -1.0020e+00, -8.0316e-02,  4.2617e-01,  6.8856e-01, -2.6948e-01],\n",
       "         [ 6.0000e-01, -1.5978e+00, -8.9449e-01, -6.2911e-01, -6.1477e-01,\n",
       "           2.5586e-01, -2.5401e-01, -7.3956e-01, -2.0371e-01, -4.6326e-01],\n",
       "         [ 3.8750e-02, -4.2154e-01,  3.7775e-01, -8.6058e-01,  1.7764e-02,\n",
       "           3.9492e-01, -1.4634e+00, -1.1529e+00, -1.2281e+00,  2.0747e-01],\n",
       "         [-2.2008e-01,  1.3724e-01,  2.1250e-01,  2.1144e+00, -3.2616e-01,\n",
       "           5.5750e-01,  1.4884e+00, -7.6525e-01,  2.7594e-01, -5.0616e-01],\n",
       "         [-5.1321e-01,  8.1687e-01,  1.1811e+00, -1.0287e+00,  1.4670e+00,\n",
       "          -9.3547e-01, -1.1072e+00, -1.4833e+00,  4.2368e-01,  9.0064e-02],\n",
       "         [ 3.9163e-01,  4.7523e-01, -2.1521e-03,  7.2757e-01,  6.2434e-01,\n",
       "          -3.1147e-01, -6.0715e-01, -7.4171e-01,  2.6527e-01, -4.7941e-01],\n",
       "         [ 1.2395e-01,  6.0411e-01, -1.6543e+00, -4.0110e-01,  2.7690e-01,\n",
       "           3.5719e-01,  7.0515e-01,  3.6820e-01, -1.4606e+00,  1.1929e+00],\n",
       "         [-7.6784e-01, -3.0026e-01,  7.2522e-01, -9.5515e-01, -1.0306e-01,\n",
       "          -7.7262e-01, -5.9150e-01,  5.2865e-01,  7.1239e-01,  1.0357e+00],\n",
       "         [ 3.4206e-01, -3.6688e-02,  6.9466e-01,  1.4884e+00,  1.4624e-01,\n",
       "           8.3402e-01,  9.7237e-02, -1.4484e-01,  7.5156e-01,  1.4737e+00],\n",
       "         [ 1.7671e-01, -1.5907e-01,  1.1412e-01, -1.2526e-01, -9.9319e-01,\n",
       "          -8.0479e-02,  3.3527e-01,  4.2147e-01, -2.0782e-01,  9.7271e-01],\n",
       "         [-7.1564e-01, -1.5193e+00,  8.8948e-01, -1.0960e+00,  1.2726e+00,\n",
       "           3.8750e-01, -1.1212e+00, -1.8245e+00, -1.3062e+00, -1.4412e+00],\n",
       "         [ 7.0047e-01,  1.4063e+00, -8.8000e-01,  9.7767e-01, -1.6015e+00,\n",
       "          -1.0840e+00,  6.1047e-01,  1.0515e+00, -4.6876e-01,  6.8840e-01],\n",
       "         [-2.6074e-01,  4.8949e-01,  2.0844e-01,  7.0449e-02,  1.0780e+00,\n",
       "          -2.1173e+00,  6.5650e-01, -4.4722e-01,  3.0438e-01, -5.4809e-02],\n",
       "         [-6.0191e-01, -3.2750e-01,  4.3900e-01, -1.6274e-01, -7.8832e-01,\n",
       "           6.6155e-01,  4.9032e-01, -9.9838e-01, -1.8031e-02,  1.4363e+00],\n",
       "         [-4.7872e-01,  1.2143e-01, -6.7831e-01, -1.0177e+00, -9.5725e-02,\n",
       "          -3.9651e-02,  1.3798e+00, -4.3245e-01, -5.0250e-01, -6.7392e-02],\n",
       "         [ 5.2617e-01, -1.0734e+00, -1.3268e+00, -9.7090e-01,  2.0150e-01,\n",
       "           1.6925e+00, -1.6040e-01, -1.4228e-02, -2.5060e-01, -3.8836e-01],\n",
       "         [ 8.0465e-01, -3.9119e-01, -3.9924e-01, -1.1395e+00,  5.4728e-01,\n",
       "          -2.4842e-01,  2.5403e-01,  1.0375e+00,  5.1315e-01, -2.7515e-01],\n",
       "         [ 1.4332e+00, -5.9840e-02, -2.8774e-01, -4.8167e-01, -2.8348e-01,\n",
       "          -2.2166e-01, -1.8329e-01, -4.4888e-01,  1.0546e-01,  6.6926e-01],\n",
       "         [-6.8482e-01, -7.8280e-01,  2.9344e-01, -1.1669e+00,  4.4532e-01,\n",
       "           1.3339e-01, -6.7304e-02, -1.1140e-01,  9.9392e-01,  2.8007e-01],\n",
       "         [-7.1314e-01,  1.1113e-01, -3.5895e-01, -7.1355e-02, -3.1644e-01,\n",
       "           3.4306e-02,  1.1089e+00,  2.8988e-01, -1.0503e+00, -8.3281e-01],\n",
       "         [ 1.0614e+00,  4.1277e-01,  2.9055e-01,  8.1434e-01,  4.0456e-01,\n",
       "           1.2728e+00,  6.4192e-01, -6.5754e-01, -1.9429e-01,  1.2608e+00],\n",
       "         [-3.3639e-01, -1.8143e-01,  1.8508e+00,  1.7476e+00,  1.2752e+00,\n",
       "           4.3151e-01, -6.5214e-01, -3.7541e-01,  7.1600e-01, -3.8145e-02],\n",
       "         [ 5.9206e-01,  1.5606e+00,  2.1010e-01,  3.8853e-01, -8.4496e-01,\n",
       "           1.4951e+00,  1.0893e+00,  1.1252e+00,  4.4273e-01, -2.3420e-01],\n",
       "         [ 1.5252e+00,  2.6027e-01, -4.3242e-01,  1.4449e-02,  6.1634e-01,\n",
       "          -4.4850e-01,  9.4798e-01, -2.6808e-01, -6.8855e-02, -1.9873e+00],\n",
       "         [-1.8120e-01,  1.5728e+00, -3.2103e-01,  7.0003e-01, -7.7256e-01,\n",
       "          -2.8721e-01,  1.1740e-01,  3.3079e-01,  4.1121e-01,  4.8900e-01],\n",
       "         [-9.6907e-02, -1.1129e+00,  6.0540e-01, -1.5890e+00,  3.3906e-01,\n",
       "           7.3889e-01,  1.9809e-01, -1.9609e-01, -3.6513e-01, -1.0904e+00],\n",
       "         [ 4.3254e-01, -1.5052e+00,  4.2115e-01, -1.1766e+00,  2.5387e-01,\n",
       "           7.3893e-01, -1.0026e+00, -2.8758e-01, -7.2669e-01, -1.0425e+00],\n",
       "         [-3.2873e-01,  5.6835e-01,  5.4097e-01,  1.2575e+00,  1.3269e+00,\n",
       "           7.5419e-01, -7.5651e-02, -1.1660e-01, -4.8866e-01,  1.1761e-01],\n",
       "         [-5.3502e-01, -4.7419e-01,  4.8361e-01,  1.2406e+00, -5.8681e-01,\n",
       "          -8.1028e-01,  2.0072e+00,  9.2112e-01,  5.5076e-01, -2.2343e-01],\n",
       "         [-1.7490e+00,  4.3088e-02,  1.1108e+00,  3.3754e-01, -8.2469e-01,\n",
       "           5.1720e-01,  3.0341e-01,  1.0826e-01,  7.2846e-01,  1.0168e+00],\n",
       "         [-8.2717e-01, -1.4009e+00, -8.1444e-01,  5.5435e-01, -5.2953e-01,\n",
       "          -3.5374e-01, -6.3046e-01, -7.9344e-01, -9.4841e-01,  1.4107e+00],\n",
       "         [ 2.7279e-01, -7.1017e-01,  4.0612e-01, -1.3606e+00, -3.7002e-01,\n",
       "           1.0006e+00,  3.0024e-01, -2.9788e-01,  1.1864e+00, -9.5876e-01],\n",
       "         [ 2.2484e+00,  3.9557e-01, -9.5117e-01, -1.4152e+00,  3.3995e-01,\n",
       "           4.8698e-01,  2.4428e-01,  6.5741e-01, -2.3591e-01,  1.1599e-01],\n",
       "         [ 9.4738e-01, -6.8279e-01,  1.2982e-01, -5.5062e-01,  1.0821e+00,\n",
       "           8.9558e-01, -9.0867e-01,  1.0821e+00, -2.9538e-01, -7.1614e-01],\n",
       "         [-1.5277e-01,  1.3266e-01,  1.9884e+00,  4.8848e-01, -3.3584e-01,\n",
       "           1.5282e-01, -1.7164e+00,  6.8825e-01, -8.4519e-01,  9.9925e-01],\n",
       "         [-1.0009e+00,  1.2143e-01, -6.1868e-01, -2.0491e-01, -3.5074e-01,\n",
       "          -4.4870e-01,  8.9757e-02,  4.7846e-01, -2.1197e-01,  1.1989e+00],\n",
       "         [-4.5501e-01, -4.6394e-01,  3.3668e-01, -1.2361e+00, -2.2107e+00,\n",
       "          -8.8400e-01,  3.7758e-02,  1.4741e-01,  4.0047e-01, -1.3036e+00],\n",
       "         [ 2.3223e-01,  4.6870e-01, -3.6682e-01,  1.1123e+00, -2.0364e-01,\n",
       "          -1.9099e+00,  1.3068e+00,  9.5749e-02,  8.7051e-01, -5.8741e-01],\n",
       "         [ 4.6309e-01, -1.1766e+00, -4.8283e-01, -7.2120e-01, -1.2365e+00,\n",
       "          -1.1493e+00,  8.3752e-01,  6.7400e-01, -6.1282e-01, -3.1621e-01],\n",
       "         [-7.4992e-01,  6.8614e-01, -5.4529e-01,  9.6849e-01, -3.3252e-01,\n",
       "          -2.3865e-01, -3.7367e-02, -2.5130e-01, -4.1512e-01,  4.2554e-01],\n",
       "         [ 2.9017e-01,  8.1649e-01, -7.4571e-01,  6.6127e-01, -4.8525e-01,\n",
       "          -1.1140e+00,  5.6398e-01, -4.7696e-01,  2.5155e-01, -1.9247e-01],\n",
       "         [-1.9444e-01,  1.1666e+00,  4.6172e-03,  4.9611e-01, -7.4960e-02,\n",
       "          -3.3675e-01,  1.1799e+00,  1.0061e+00,  5.5391e-01,  2.0918e-01],\n",
       "         [ 1.3995e+00, -9.7225e-01,  5.3298e-01, -8.9130e-01, -5.5486e-02,\n",
       "           5.6769e-01, -9.4543e-01, -9.8175e-01, -1.1170e+00,  2.1291e-01],\n",
       "         [-7.3051e-01,  1.6558e-01,  4.1108e-01, -1.3752e+00, -9.5860e-01,\n",
       "           1.6232e+00,  2.5983e-01, -3.6357e-01,  3.1501e-01, -7.5100e-01],\n",
       "         [ 1.0919e+00, -2.3711e-02, -9.3084e-01,  1.6309e-01,  1.7121e-01,\n",
       "           7.5380e-01, -5.0954e-02, -6.4645e-03,  1.4992e+00, -1.7334e+00],\n",
       "         [-1.9385e+00, -5.3123e-01, -9.5721e-01, -9.5504e-01, -5.9101e-02,\n",
       "          -1.8755e-01, -5.0124e-01, -1.5552e-01,  9.2505e-01,  1.7382e+00],\n",
       "         [ 1.2745e-03,  6.8829e-01,  5.0260e-01, -1.0159e+00, -1.2045e-01,\n",
       "           1.8409e+00, -1.5476e+00,  6.9053e-01,  9.5711e-01,  1.2150e+00],\n",
       "         [-1.6119e+00, -1.4401e+00, -1.3807e+00, -7.2374e-01, -9.5046e-01,\n",
       "          -6.8054e-01, -1.4475e-01, -4.1617e-01,  9.1892e-01, -2.4742e-01],\n",
       "         [-1.8861e+00, -8.6365e-01, -5.2575e-01, -1.9484e-01,  4.6879e-01,\n",
       "          -1.0191e+00,  4.1777e-01, -9.7245e-01, -1.4334e+00,  9.6625e-02],\n",
       "         [ 6.7026e-01, -4.9550e-01,  1.0114e-01,  4.8839e-01, -1.3998e+00,\n",
       "           1.0818e+00,  3.7294e-01, -3.3753e-01,  2.8909e-01,  8.9740e-01],\n",
       "         [-9.6438e-01,  4.1024e-01,  4.0869e-01,  2.4434e-01, -4.7588e-01,\n",
       "          -2.4627e-01, -6.3544e-01,  6.7025e-01,  5.5671e-01, -8.6983e-01],\n",
       "         [-1.0096e+00, -4.3744e-01,  9.2819e-01, -6.3634e-01, -3.4450e-02,\n",
       "          -6.8208e-02, -9.1599e-01, -2.9248e-02,  9.1047e-01, -1.7763e+00],\n",
       "         [-4.3129e-01,  1.7862e+00,  1.4835e+00,  5.9994e-01, -1.4423e+00,\n",
       "          -3.5068e-01, -7.2982e-01, -1.1366e+00,  3.0973e-01,  1.2011e+00],\n",
       "         [-1.1412e+00,  2.2270e+00,  4.3667e-02,  6.9132e-01, -1.9962e-01,\n",
       "          -3.9646e-01, -2.7940e-01, -1.2419e+00,  1.2479e-01,  6.0747e-01],\n",
       "         [-8.3766e-01, -5.5003e-01,  8.6871e-02, -1.5304e+00, -4.7588e-01,\n",
       "           2.6402e-01,  9.6908e-03, -5.2894e-01, -2.0231e+00, -5.7213e-01],\n",
       "         [-4.9119e-01,  1.9568e-01, -9.1218e-01, -3.8463e-01, -1.1501e-01,\n",
       "          -5.8631e-01,  5.0269e-01,  3.1187e-02, -3.4393e-01,  1.3793e-02],\n",
       "         [-1.1841e-01,  7.1716e-01, -8.8054e-01,  2.1338e-01, -1.4241e-01,\n",
       "          -1.9634e+00, -7.5418e-01,  7.2281e-02,  4.4684e-02, -8.6597e-02],\n",
       "         [ 2.9387e-02,  2.5487e-01, -3.2320e-01,  2.2140e+00,  8.9913e-01,\n",
       "           1.4164e-01,  1.0162e-02,  9.3008e-01,  9.2756e-02, -4.2773e-01],\n",
       "         [ 4.7650e-01,  1.5069e-01,  4.2380e-01,  1.6194e-01,  2.1650e+00,\n",
       "           7.6680e-01, -5.5666e-01,  2.1148e+00, -5.8737e-01, -8.2412e-01],\n",
       "         [ 9.5731e-01, -2.8075e-01,  1.1026e+00, -7.9708e-01,  1.1122e-01,\n",
       "          -9.2031e-02,  2.0550e+00, -1.0169e+00, -1.4745e+00, -1.7374e+00],\n",
       "         [-3.9593e-01, -1.5029e+00,  1.2436e+00,  8.3273e-01,  6.1480e-01,\n",
       "          -1.1130e+00,  1.9336e-02,  2.6315e-01, -9.7937e-01, -1.2619e+00],\n",
       "         [ 5.3590e-01,  4.5689e-01,  1.6413e-01, -3.9836e-01, -1.5963e+00,\n",
       "          -5.8057e-01,  3.0460e-01,  1.2098e+00, -7.2910e-01, -9.2077e-01],\n",
       "         [-2.8523e-01,  1.1990e+00,  1.6456e-01,  4.9162e-01, -3.3812e-01,\n",
       "           4.1611e-01,  4.8307e-01, -9.2338e-01,  2.7370e-01, -3.1257e-01],\n",
       "         [ 7.4597e-01, -1.5168e-01, -1.3917e+00,  4.5898e-01, -2.7524e-01,\n",
       "          -1.5729e+00, -6.8887e-01,  4.5827e-01, -1.0201e+00, -1.4100e+00],\n",
       "         [-1.9230e+00,  8.7095e-01,  7.3482e-01,  1.4416e-01, -5.7956e-01,\n",
       "           4.9401e-01,  1.0016e+00, -6.9875e-01, -5.5179e-02,  5.0296e-01],\n",
       "         [-2.1364e+00, -1.1744e+00, -3.1485e-03,  1.7311e+00, -7.4570e-01,\n",
       "           7.0955e-01,  5.5550e-01, -2.2670e-01, -5.8594e-01,  1.7244e+00],\n",
       "         [ 7.0905e-01,  7.1837e-01,  7.6817e-01, -6.0223e-01,  2.7826e-01,\n",
       "          -8.3938e-01,  1.2924e-01, -1.4249e-01,  1.1611e+00, -7.2258e-01],\n",
       "         [-6.3919e-01, -1.2260e+00, -3.8575e-01,  1.1126e+00, -6.7480e-01,\n",
       "          -7.5854e-01, -1.0236e-01,  5.2696e-02,  4.0965e-01, -6.5900e-01],\n",
       "         [ 9.9258e-01, -7.4313e-01,  1.6512e-01, -3.4712e-01, -1.4979e+00,\n",
       "           1.0953e+00, -2.2467e-01,  1.8371e+00, -5.1466e-01,  1.2920e+00],\n",
       "         [ 1.1076e+00, -9.1919e-01, -1.5097e+00, -1.4982e-01,  4.0610e-01,\n",
       "           2.0472e+00, -2.9776e-02,  1.1686e+00, -6.1361e-01, -6.8786e-01],\n",
       "         [ 2.7926e-01, -5.9942e-02,  6.3627e-01,  2.3364e-01,  8.3133e-02,\n",
       "           4.9382e-01,  5.2632e-01,  2.4614e-01,  3.8009e-02, -1.6327e-01],\n",
       "         [ 3.2244e-02,  6.4104e-01,  5.9688e-01, -3.8162e-01,  5.2771e-01,\n",
       "           2.8540e-01, -8.3586e-01, -3.8065e-01,  1.4722e+00, -4.5572e-01],\n",
       "         [ 9.2032e-01,  1.5266e+00, -1.6184e-01, -2.6117e-01,  4.0245e-01,\n",
       "           7.2570e-01,  1.6921e-01,  8.3530e-01, -1.0615e-01,  1.1409e-01],\n",
       "         [ 6.1376e-01, -5.4827e-01,  8.7904e-01,  2.7496e-01,  1.3071e+00,\n",
       "          -3.1013e-01, -6.6803e-01,  3.5338e-01,  7.6165e-01, -1.5929e-01],\n",
       "         [ 6.6666e-01,  8.6591e-01,  5.1788e-01, -4.8687e-01, -1.5393e-01,\n",
       "           3.8464e-01, -1.0395e+00, -7.8618e-01, -9.1343e-01,  1.1646e+00],\n",
       "         [ 2.6672e-01,  1.0897e-02, -1.2225e+00,  4.3788e-01,  8.7326e-01,\n",
       "          -5.8626e-01,  3.9738e-01,  7.5146e-01,  2.9850e-01,  9.5390e-01],\n",
       "         [ 2.5287e-01, -7.1538e-01,  7.0886e-02, -3.6399e-01, -8.9907e-02,\n",
       "          -1.9393e-01,  2.5925e-02,  4.0060e-01, -3.6565e-01, -1.1429e+00],\n",
       "         [-4.6322e-01, -1.4435e+00, -8.9028e-02, -2.0404e-01, -7.5393e-01,\n",
       "           1.9064e-01, -2.4816e-01,  4.1902e-01,  7.5915e-01,  1.4460e+00],\n",
       "         [ 1.7254e+00,  1.4931e+00, -1.1247e+00, -1.3941e+00, -4.5003e-01,\n",
       "          -1.7077e-01,  8.1850e-01, -1.5780e+00, -2.2212e-01,  2.1556e-01],\n",
       "         [ 7.4363e-01,  1.7529e-01,  6.8270e-01,  8.8933e-01,  1.2771e+00,\n",
       "           5.8502e-01,  3.5907e-01,  1.4962e-01, -2.8394e+00, -1.2446e+00],\n",
       "         [-8.0703e-01, -5.4500e-01, -6.6091e-01, -2.2184e-01,  5.2362e-01,\n",
       "           9.8846e-01,  5.4207e-01, -3.6751e-01,  5.7835e-01, -4.5583e-01],\n",
       "         [ 1.6933e-01, -8.2115e-01, -1.2525e-01,  1.2773e+00,  9.7513e-01,\n",
       "          -4.2669e-01, -1.5703e+00,  1.9465e-01,  1.3163e+00, -8.4945e-01],\n",
       "         [-2.5988e-02,  1.1678e+00,  4.5201e-01, -7.5168e-01,  6.8630e-01,\n",
       "           5.6447e-01, -8.5364e-01, -2.0115e+00,  9.0034e-01,  1.9715e+00],\n",
       "         [ 7.6932e-01,  6.0204e-02,  3.8202e-01,  9.9887e-01, -5.1136e-01,\n",
       "          -2.1993e-01,  2.2111e+00,  1.4749e+00,  2.3275e-01, -5.3071e-01],\n",
       "         [ 4.2042e-01, -6.3174e-01,  7.5132e-01,  2.9162e+00, -2.0780e-01,\n",
       "          -2.0309e-01,  4.8010e-02, -8.4392e-02,  4.7896e-01,  6.7541e-01],\n",
       "         [-4.8911e-01, -1.2811e+00, -1.1141e+00,  2.0090e-01,  1.4168e+00,\n",
       "          -1.5888e+00, -2.2810e-01, -1.3014e+00,  5.8594e-01,  2.5264e+00],\n",
       "         [ 2.7862e-01,  5.8261e-01,  1.7655e+00,  1.3574e-02,  6.8290e-02,\n",
       "          -1.1196e+00, -1.0420e+00, -4.4354e-01, -1.3242e-01,  2.0780e-01],\n",
       "         [-9.0382e-02,  1.1465e-01, -3.0300e-01, -1.0425e+00,  2.2525e-01,\n",
       "           1.0492e+00, -2.2430e+00, -3.1286e-01, -6.4831e-01,  1.7862e-01],\n",
       "         [ 1.6747e+00, -2.4987e-01, -2.2748e+00,  1.6718e-01,  5.9066e-01,\n",
       "          -1.6580e+00,  8.9366e-02, -1.0999e+00, -3.1897e-01, -1.1982e+00],\n",
       "         [-1.0641e+00,  3.1740e-01, -2.4432e-01, -5.5919e-01, -3.9460e-01,\n",
       "           6.4646e-02,  8.2190e-01,  2.3919e-01, -1.3869e+00,  9.7885e-02],\n",
       "         [-3.2839e-01,  1.7507e+00, -1.0317e-01, -5.8660e-01, -2.6605e-01,\n",
       "          -4.6666e-01, -3.7666e-01, -1.4195e+00,  7.0670e-01,  7.6121e-01],\n",
       "         [-2.1380e-01, -1.7191e+00,  8.0545e-01, -1.4080e+00,  1.9094e+00,\n",
       "           1.2201e+00, -1.2971e+00, -8.7909e-01,  1.1304e+00, -1.2843e+00]],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "x = torch.randn(N, D_in, device=device)\n",
    "y = torch.randn(N, D_out, device=device)\n",
    "w1 = torch.randn(D_in, H, device=device, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, requires_grad=True)\n",
    "\n",
    "for t in range(500) :\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "    \n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad() :\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()\n",
    "        \n",
    "w1, w2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2532c73",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### New Autograd Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b69880f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T07:58:03.073729Z",
     "start_time": "2021-06-18T07:58:03.058738Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class MyReLU(torch.autograd.Function) :\n",
    "    @staticmethod\n",
    "    def forward(ctx, x) :\n",
    "        ctx.save_for_backward(x)\n",
    "        return x.clamp(min=0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_y) :\n",
    "        x, = ctx.saved_tensors\n",
    "        grad_input = grad_y.clone()\n",
    "        grad_input[x < 0] = 0\n",
    "        return grad_input\n",
    "    \n",
    "def my_relu(x) :\n",
    "    return MyReLU.apply(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed8c728b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T08:09:50.643786Z",
     "start_time": "2021-06-18T08:09:50.123036Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "x = torch.randn(N, D_in, device=device)\n",
    "y = torch.randn(N, D_out, device=device)\n",
    "w1 = torch.randn(D_in, H, device=device, requires_grad=True)\n",
    "w2 = torch.randn(H, D_out, device=device, requires_grad=True)\n",
    "\n",
    "for t in range(500) :\n",
    "    y_pred = my_relu(x.mm(w1)).mm(w2)\n",
    "    \n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad() :\n",
    "        w1 -= learning_rate * w1.grad\n",
    "        w2 -= learning_rate * w2.grad\n",
    "        w1.grad.zero_()\n",
    "        w2.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f3bca1",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### nn (Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e86f7ea7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T08:09:59.324928Z",
     "start_time": "2021-06-18T08:09:58.671379Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "x = torch.randn(N, D_in, device=device)\n",
    "y = torch.randn(N, D_out, device=device)\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out))\n",
    "\n",
    "learning_rate = 1e-2\n",
    "for t in range(500) :\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    loss = torch.nn.functional.mse_loss(y_pred, y)\n",
    "    loss.backward()\n",
    "    \n",
    "    with torch.no_grad() :\n",
    "        for param in model.parameters() :\n",
    "            param -= learning_rate * param.grad\n",
    "    \n",
    "    model.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919fafdb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b44aadca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T08:10:01.921993Z",
     "start_time": "2021-06-18T08:10:00.789322Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "x = torch.randn(N, D_in, device=device)\n",
    "y = torch.randn(N, D_out, device=device)\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out))\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(500) :\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    loss = torch.nn.functional.mse_loss(y_pred, y)\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a13439b",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 새로운 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe825ebf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T08:15:47.495777Z",
     "start_time": "2021-06-18T08:15:46.931950Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class TwoLayerNet(torch.nn.Module) :\n",
    "    def __init__(self, D_in, H, D_out) :\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        h_relu = self.linear1(x).clamp(min=0)\n",
    "        y_pred = self.linear2(h_relu)\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "x = torch.randn(N, D_in, device=device)\n",
    "y = torch.randn(N, D_out, device=device)\n",
    "\n",
    "model = TwoLayerNet(D_in, H, D_out)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(500) :\n",
    "    y_pred = model(x)\n",
    "    loss = torch.nn.functional.mse_loss(y_pred, y)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307bebab",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "866e2b68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T08:22:40.389357Z",
     "start_time": "2021-06-18T08:22:40.146156Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "EPOCH = 20\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "x = torch.randn(N, D_in, device=device)\n",
    "y = torch.randn(N, D_out, device=device)\n",
    "\n",
    "loader = DataLoader(TensorDataset(x, y), batch_size=8)\n",
    "model = TwoLayerNet(D_in, H, D_out)\n",
    "\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(EPOCH) :\n",
    "    for x_batch, y_batch in loader :\n",
    "        y_pred = model(x_batch)\n",
    "        loss = torch.nn.functional.mse_loss(y_pred, y_batch)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d676d20",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9092dd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T08:25:30.141860Z",
     "start_time": "2021-06-18T08:25:28.659290Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to C:\\Users\\sosim/.cache\\torch\\hub\\checkpoints\\mobilenet_v3_small-047dcff4.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bcb53e3de0e4e6bb6798e58f43534d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/9.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MobileNetV3(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBNActivation(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): SqueezeExcitation(\n",
       "          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ConvBNActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvBNActivation(\n",
       "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): ConvBNActivation(\n",
       "          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): ConvBNActivation(\n",
       "          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): ConvBNActivation(\n",
       "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=576, out_features=1024, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=True)\n",
       "    (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "\n",
    "mobileV3 = torchvision.models.mobilenet_v3_small(pretrained=True)\n",
    "mobileV3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adeb50e",
   "metadata": {},
   "source": [
    "## TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f8793ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T08:35:16.711912Z",
     "start_time": "2021-06-18T08:35:08.837609Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec4eceb",
   "metadata": {},
   "source": [
    "### Dynamic, Static Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462aea36",
   "metadata": {},
   "source": [
    "#### v2 이전 (실행 안됨)\n",
    "  - Static Graph 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3d181ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T08:40:47.265993Z",
     "start_time": "2021-06-18T08:40:46.708784Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-87fe5ab82548>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mw1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mw2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "N, D, H = 64, 1000, 100\n",
    "x = tf.placeholder(tf.float32, shape=(N, D))\n",
    "y = tf.placeholder(tf.float32, shape=(N, D))\n",
    "w1 = tf.placeholder(tf.float32, shape=(D, H))\n",
    "w2 = tf.placeholder(tf.float32, shape=(H, D))\n",
    "\n",
    "h = tf.maximum(tf.matmul(x, w1), 0)\n",
    "y_pred = tf.matmul(h, w2)\n",
    "diff = y_pred - y\n",
    "loss = tf.reduce_mean(tf.reduce_sum(diff ** 2, axis=1))\n",
    "\n",
    "grad_w1, grad_w2 = tf.gradients(loss, [w1, w2])\n",
    "# ↑ 그래프를 쌓고\n",
    "# ↓ 이후에 연산\n",
    "with tf.Session() as sess :\n",
    "    values = {x : np.random.randn(N, D),\n",
    "              w1: np.random.randn(D, H),\n",
    "              w2: np.random.randn(H, D),\n",
    "              y : np.random.randn(N, D),}\n",
    "    \n",
    "    out = sess.run([loss, grad_w1, grad_w2], feed_dict=value)\n",
    "    loss_val, graw_w1_val, grad_w2_val = out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9df5f7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### v2 이후\n",
    "  - Dynaminc Graph 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c6d77ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T08:51:16.719671Z",
     "start_time": "2021-06-18T08:51:16.692688Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "N, D, H = 64, 1000, 100\n",
    "x = tf.convert_to_tensor(np.random.randn(N, D), np.float32)\n",
    "y = tf.convert_to_tensor(np.random.randn(N, D), np.float32)\n",
    "w1 = tf.Variable(tf.random.uniform((D, H)))\n",
    "w2 = tf.Variable(tf.random.uniform((H, D)))\n",
    "\n",
    "with tf.GradientTape() as tape :\n",
    "    h = tf.maximum(tf.matmul(x, w1), 0)\n",
    "    y_pred = tf.matmul(h, w2)\n",
    "    diff = y_pred - y\n",
    "    loss = tf.reduce_mean(tf.reduce_sum(diff ** 2, axis=1))\n",
    "    \n",
    "gradients = tape.gradient(loss, [w1, w2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e5636a",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b7efebb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T08:53:03.629696Z",
     "start_time": "2021-06-18T08:53:03.575727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=1>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N, D, H = 64, 1000, 100\n",
    "x = tf.convert_to_tensor(np.random.randn(N, D), np.float32)\n",
    "y = tf.convert_to_tensor(np.random.randn(N, D), np.float32)\n",
    "w1 = tf.Variable(tf.random.uniform((D, H)))\n",
    "w2 = tf.Variable(tf.random.uniform((H, D)))\n",
    "\n",
    "learning_rate = 1e-6\n",
    "optimizer = tf.optimizers.SGD(learning_rate)\n",
    "\n",
    "with tf.GradientTape() as tape :\n",
    "    h = tf.maximum(tf.matmul(x, w1), 0)\n",
    "    y_pred = tf.matmul(h, w2)\n",
    "    diff = y_pred - y\n",
    "    loss = tf.reduce_mean(tf.reduce_sum(diff ** 2, axis=1))\n",
    "    \n",
    "gradients = tape.gradient(loss, [w1, w2])\n",
    "optimizer.apply_gradients(zip(gradients, [w1, w2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64abd49",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "004f70c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T08:55:00.102257Z",
     "start_time": "2021-06-18T08:54:59.804684Z"
    }
   },
   "outputs": [],
   "source": [
    "EPOCH = 50\n",
    "N, D, H = 64, 1000, 100\n",
    "x = tf.convert_to_tensor(np.random.randn(N, D), np.float32)\n",
    "y = tf.convert_to_tensor(np.random.randn(N, D), np.float32)\n",
    "w1 = tf.Variable(tf.random.uniform((D, H)))\n",
    "w2 = tf.Variable(tf.random.uniform((H, D)))\n",
    "\n",
    "learning_rate = 1e-6\n",
    "optimizer = tf.optimizers.SGD(learning_rate)\n",
    "\n",
    "for t in range(EPOCH) :\n",
    "    with tf.GradientTape() as tape :\n",
    "        h = tf.maximum(tf.matmul(x, w1), 0)\n",
    "        y_pred = tf.matmul(h, w2)\n",
    "        loss = tf.losses.MeanSquaredError()(y_pred, y)\n",
    "\n",
    "    gradients = tape.gradient(loss, [w1, w2])\n",
    "    optimizer.apply_gradients(zip(gradients, [w1, w2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3f09e3",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11c1a8ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T09:01:25.193976Z",
     "start_time": "2021-06-18T09:01:24.818835Z"
    }
   },
   "outputs": [],
   "source": [
    "EPOCH = 50\n",
    "N, D, H = 64, 1000, 100\n",
    "x = tf.convert_to_tensor(np.random.randn(N, D), np.float32)\n",
    "y = tf.convert_to_tensor(np.random.randn(N, D), np.float32)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(H, input_shape=(D, ), activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(D))\n",
    "\n",
    "learning_rate = 1e-6\n",
    "optimizer = tf.optimizers.SGD(learning_rate)\n",
    "\n",
    "for t in range(EPOCH) :\n",
    "    with tf.GradientTape() as tape :\n",
    "        y_pred = model(x)\n",
    "        loss = tf.losses.MeanSquaredError()(y_pred, y)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92543046",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T09:03:15.682882Z",
     "start_time": "2021-06-18T09:03:14.724316Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1698\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1698\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 0s/step - loss: 1.1698\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 997us/step - loss: 1.1698\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1698\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1698\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 997us/step - loss: 1.1698\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1698\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1698\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1698\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1698\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1698\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1698\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1698\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1698\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1698\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1698\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.1698\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1698\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1698\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.1698\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1698\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 974us/step - loss: 1.1698\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1698\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1698\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1698\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1698\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1698\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1698\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1698\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1698\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1698\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1698\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 997us/step - loss: 1.1698\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1698\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1698\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1698\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1698\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1698\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 998us/step - loss: 1.1698\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1698\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1698\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1698\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1698\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 995us/step - loss: 1.1698\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1698\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1698\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 999us/step - loss: 1.1698\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1698\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1698\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 50\n",
    "N, D, H = 64, 1000, 100\n",
    "x = tf.convert_to_tensor(np.random.randn(N, D), np.float32)\n",
    "y = tf.convert_to_tensor(np.random.randn(N, D), np.float32)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(H, input_shape=(D, ), activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(D))\n",
    "\n",
    "learning_rate = 1e-6\n",
    "optimizer = tf.optimizers.SGD(learning_rate)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=optimizer)\n",
    "history = model.fit(x, y, epochs=EPOCH, batch_size=N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7cfd50",
   "metadata": {},
   "source": [
    "### `@tf.function`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "964bab79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T09:08:43.590268Z",
     "start_time": "2021-06-18T09:08:43.423393Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static Graph : 0.1000317999996696\n",
      "Dynamic Graph : 0.018434499999784748\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "EPOCH = 50\n",
    "N, D, H = 64, 1000, 100\n",
    "x = tf.convert_to_tensor(np.random.randn(N, D), np.float32)\n",
    "y = tf.convert_to_tensor(np.random.randn(N, D), np.float32)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(H, input_shape=(D, ), activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(D))\n",
    "\n",
    "learning_rate = 1e-6\n",
    "optimizer = tf.optimizers.SGD(learning_rate)\n",
    "\n",
    "@tf.function\n",
    "def model_static(x, y) :\n",
    "    y_pred = model(x)\n",
    "    loss = tf.losses.MeanSquaredError()(y_pred, y)\n",
    "    return y_pred, loss\n",
    "\n",
    "def model_dynamic(x, y) :\n",
    "    y_pred = model(x)\n",
    "    loss = tf.losses.MeanSquaredError()(y_pred, y)\n",
    "    return y_pred, loss\n",
    "\n",
    "print('Static Graph :', timeit.timeit(lambda : model_static(x, y), number=10))\n",
    "print('Dynamic Graph :', timeit.timeit(lambda : model_dynamic(x, y), number=10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
